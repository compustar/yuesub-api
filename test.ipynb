{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pytubefix import YouTube\n",
    "\n",
    "# urls = 'https://www.youtube.com/watch?v=H2dEZftiAIk'\n",
    "\n",
    "# entry = YouTube(urls).title\n",
    "\n",
    "# vid = YouTube(urls)\n",
    "# audio_download = vid.streams.get_audio_only()\n",
    "# audio_download.download(mp3=True, filename=\"H2dEZftiAIk\", output_path=\"/tmp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import youtube_dl\n",
    "\n",
    "# ydl_opts = {\n",
    "#     'format': 'worstaudio/worst',\n",
    "#     'postprocessors': [{\n",
    "#         'key': 'FFmpegExtractAudio',\n",
    "#         'preferredcodec': 'mp3',\n",
    "#         'preferredquality': '192',\n",
    "#     }],\n",
    "# }\n",
    "# with youtube_dl.YoutubeDL(ydl_opts) as ydl:\n",
    "#     ydl.download(['http://www.youtube.com/watch?v=C0DPdy98e4c'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/josephcheng/Projects/yue-subtitle-api/.venv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n",
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "from utils import download_youtube_audio, transcribe, asr_model, bert_model, corrector, load_dict, asr, to_srt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91mget_throttling_function_name: could not find match for multiple in https://youtube.com/s/player/2f238d39/player_ias.vflset/en_US/base.js\u001b[0m\n",
      "None\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'transcription' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m audio_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m      6\u001b[0m   transcription \u001b[38;5;241m=\u001b[39m transcribe(audio_file)\n\u001b[0;32m----> 8\u001b[0m \u001b[43mtranscription\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'transcription' is not defined"
     ]
    }
   ],
   "source": [
    "audio_file = download_youtube_audio('sRAFDyl1RfA')\n",
    "\n",
    "print(audio_file)\n",
    "\n",
    "if audio_file is not None:\n",
    "  transcription = transcribe(audio_file)\n",
    "\n",
    "transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.\n",
      "Transcribing: 100%|██████████| 26/26 [00:06<00:00,  3.93it/s]\n",
      "Converting to Traditional Chinese: 100%|██████████| 61/61 [00:31<00:00,  1.93it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[TranscribeResult(text=嗯, start_time=3.884, end_time=4.46),\n",
       " TranscribeResult(text=啊嗱啦啦嗱啦啦嗱啦啦嗱喂喂喂啊, start_time=8.133607954545456, end_time=13.88471590909091),\n",
       " TranscribeResult(text=你做咩坐咗, start_time=13.88471590909091, end_time=14.596193181818183),\n",
       " TranscribeResult(text=我張椅啊博士啊, start_time=14.596193181818183, end_time=16.374886363636364),\n",
       " TranscribeResult(text=我見, start_time=16.434176136363636, end_time=16.789914772727272),\n",
       " TranscribeResult(text=你都唔坐啦, start_time=16.789914772727272, end_time=17.679261363636364),\n",
       " TranscribeResult(text=我咪坐下咯, start_time=17.738551136363636, end_time=18.6871875),\n",
       " TranscribeResult(text=你想着巢溝占啊啊, start_time=18.924346590909092, end_time=21.177357954545453),\n",
       " TranscribeResult(text=博士啊, start_time=21.71096590909091, end_time=22.303863636363637),\n",
       " TranscribeResult(text=咩叫着巢溝占啊, start_time=22.42244318181818, end_time=24.141846590909093),\n",
       " TranscribeResult(text=你俾翻張椅我坐咧, start_time=24.31971590909091, end_time=25.742670454545454),\n",
       " TranscribeResult(text=我就講俾你知啦咁啊, start_time=25.742670454545454, end_time=28.470000000000002),\n",
       " TranscribeResult(text=口呢個古仔咧, start_time=30.140048076923076, end_time=31.74512019230769),\n",
       " TranscribeResult(text=係出自詩經噶有一隻腳辛辛苦苦咁捉足去巢噃終都完靜咗啦大▁b▁啊喺▁b▁啊, start_time=31.74512019230769, end_time=48.74699519230769),\n",
       " TranscribeResult(text=我哋以後有屋住啦, start_time=49.04423076923077, end_time=50.589855769230766),\n",
       " TranscribeResult(text=哇好啦啊, start_time=51.36266826923077, end_time=53.800000000000004),\n",
       " TranscribeResult(text=哎呀落雨天, start_time=57.39370967741935, end_time=58.736935483870965),\n",
       " TranscribeResult(text=今次真係被加火啦, start_time=58.84887096774194, end_time=60.36),\n",
       " TranscribeResult(text=哎哎呀好凍啊, start_time=64.74298804780878, end_time=66.69406374501993),\n",
       " TranscribeResult(text=好凍啊, start_time=66.93055776892432, end_time=67.75828685258965),\n",
       " TranscribeResult(text=哎呀外面落咁大雨你不如入嚟俾下先好啦, start_time=68.11302788844623, end_time=71.60131474103586),\n",
       " TranscribeResult(text=唔該曬你啊啊長媽媽, start_time=71.66043824701197, end_time=74.85310756972112),\n",
       " TranscribeResult(text=你啊真係好人嘅啦, start_time=74.85310756972112, end_time=76.03557768924304),\n",
       " TranscribeResult(text=你哋仔女又活潑又可愛添啊, start_time=76.09470119521913, end_time=79.11000000000001),\n",
       " TranscribeResult(text=嗯, start_time=88.58864197530865, end_time=88.94012345679013),\n",
       " TranscribeResult(text=啊停咗雨啦, start_time=89.40876543209878, end_time=90.46320987654322),\n",
       " TranscribeResult(text=我要出去玩嘢食下嚇, start_time=90.5217901234568, end_time=91.86913580246915),\n",
       " TranscribeResult(text=哇, start_time=92.2791975308642, end_time=92.51351851851852),\n",
       " TranscribeResult(text=好嘢好啦有嘢食, start_time=92.5720987654321, end_time=94.32950617283952),\n",
       " TranscribeResult(text=你放心去咧, start_time=94.32950617283952, end_time=95.32537037037038),\n",
       " TranscribeResult(text=我會幫你看住佢哋嘅咧, start_time=95.38395061728396, end_time=97.61),\n",
       " TranscribeResult(text=爸爸拜爸爸, start_time=100.61846153846155, end_time=103.0),\n",
       " TranscribeResult(text=嗯, start_time=104.16285714285715, end_time=104.43666666666667),\n",
       " TranscribeResult(text=真係舒服, start_time=104.54619047619047, end_time=105.9152380952381),\n",
       " TranscribeResult(text=係啊哎呀哎呀哎呀哎呀, start_time=107.50421052631579, end_time=109.0),\n",
       " TranscribeResult(text=啊喂乜你噉霸王噶, start_time=110.33965986394558, end_time=112.2095918367347),\n",
       " TranscribeResult(text=乜嘢霸王啊, start_time=112.38489795918369, end_time=113.31986394557825),\n",
       " TranscribeResult(text=咪阻住我瞓覺啊快啲扯啊, start_time=113.43673469387757, end_time=115.65727891156465),\n",
       " TranscribeResult(text=你個頭係我哋嘅, start_time=115.77414965986395, end_time=118.17000000000002),\n",
       " TranscribeResult(text=你再唔走咧, start_time=118.84175438596492, end_time=119.90508771929825),\n",
       " TranscribeResult(text=繫唔係想大一身咁啊, start_time=119.96105263157895, end_time=121.5840350877193),\n",
       " TranscribeResult(text=啊, start_time=122.08571428571429, end_time=122.41714285714286),\n",
       " TranscribeResult(text=哈, start_time=127.01894736842105, end_time=127.54),\n",
       " TranscribeResult(text=誒啊啊, start_time=129.96066666666667, end_time=130.38733333333332),\n",
       " TranscribeResult(text=唉啊啊, start_time=130.98250000000002, end_time=131.66150000000002),\n",
       " TranscribeResult(text=ok, start_time=133.45624999999998, end_time=133.78),\n",
       " TranscribeResult(text=嗯, start_time=134.59, end_time=134.98000000000002),\n",
       " TranscribeResult(text=哇, start_time=136.4077777777778, end_time=136.74222222222224),\n",
       " TranscribeResult(text=你快啲起身啊, start_time=137.7467213114754, end_time=138.64901639344262),\n",
       " TranscribeResult(text=你做咩霸咗, start_time=138.64901639344262, end_time=139.32573770491803),\n",
       " TranscribeResult(text=我個巢啊, start_time=139.32573770491803, end_time=140.51),\n",
       " TranscribeResult(text=你有冇搞錯啊, start_time=141.18307692307692, end_time=142.3623076923077),\n",
       " TranscribeResult(text=呢個頭邊度作住, start_time=142.4746153846154, end_time=143.5976923076923),\n",
       " TranscribeResult(text=你個名啊, start_time=143.5976923076923, end_time=144.44),\n",
       " TranscribeResult(text=你好快啲走啊, start_time=147.3583783783784, end_time=148.98000000000002),\n",
       " TranscribeResult(text=呢個就係雀巢勾戰嘅故事啦, start_time=153.42884943181818, end_time=155.48006569602273),\n",
       " TranscribeResult(text=如果話人無你強佔他人嘅嘢, start_time=155.59727805397728, end_time=157.76570667613638),\n",
       " TranscribeResult(text=就可以用雀巢勾佔呢句成語啦, start_time=157.88291903409092, end_time=160.05134765625002),\n",
       " TranscribeResult(text=喂喂, start_time=160.2857723721591, end_time=160.696015625),\n",
       " TranscribeResult(text=你明唔明白啊, start_time=160.696015625, end_time=161.75092684659091),\n",
       " TranscribeResult(text=博士我明白啦, start_time=162.1611700994318, end_time=163.2746875)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcription = transcribe('/Users/josephcheng/Desktop/ntDp_odgY9s_2.mp3')\n",
    "\n",
    "transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0\\n00:00:03,884 --> 00:00:04,460\\n嗯\\n\\n1\\n00:00:08,133 --> 00:00:13,884\\n啊嗱啦啦嗱啦啦嗱啦啦嗱喂喂喂啊\\n\\n2\\n00:00:13,884 --> 00:00:14,596\\n你做咩坐咗\\n\\n3\\n00:00:14,596 --> 00:00:16,374\\n我張椅啊博士啊\\n\\n4\\n00:00:16,434 --> 00:00:16,789\\n我見\\n\\n5\\n00:00:16,789 --> 00:00:17,679\\n你都唔坐啦\\n\\n6\\n00:00:17,738 --> 00:00:18,687\\n我咪坐下咯\\n\\n7\\n00:00:18,924 --> 00:00:21,177\\n你想着巢溝占啊啊\\n\\n8\\n00:00:21,710 --> 00:00:22,303\\n博士啊\\n\\n9\\n00:00:22,422 --> 00:00:24,141\\n咩叫着巢溝占啊\\n\\n10\\n00:00:24,319 --> 00:00:25,742\\n你俾翻張椅我坐咧\\n\\n11\\n00:00:25,742 --> 00:00:28,470\\n我就講俾你知啦咁啊\\n\\n12\\n00:00:30,140 --> 00:00:31,745\\n口呢個古仔咧\\n\\n13\\n00:00:31,745 --> 00:00:48,746\\n係出自詩經噶有一隻腳辛辛苦苦咁捉足去巢噃終都完靜咗啦大▁b▁啊喺▁b▁啊\\n\\n14\\n00:00:49,044 --> 00:00:50,589\\n我哋以後有屋住啦\\n\\n15\\n00:00:51,362 --> 00:00:53,800\\n哇好啦啊\\n\\n16\\n00:00:57,393 --> 00:00:58,736\\n哎呀落雨天\\n\\n17\\n00:00:58,848 --> 00:01:00,360\\n今次真係被加火啦\\n\\n18\\n00:01:04,742 --> 00:01:06,694\\n哎哎呀好凍啊\\n\\n19\\n00:01:06,930 --> 00:01:07,758\\n好凍啊\\n\\n20\\n00:01:08,113 --> 00:01:11,601\\n哎呀外面落咁大雨你不如入嚟俾下先好啦\\n\\n21\\n00:01:11,660 --> 00:01:14,853\\n唔該曬你啊啊長媽媽\\n\\n22\\n00:01:14,853 --> 00:01:16,035\\n你啊真係好人嘅啦\\n\\n23\\n00:01:16,094 --> 00:01:19,110\\n你哋仔女又活潑又可愛添啊\\n\\n24\\n00:01:28,588 --> 00:01:28,940\\n嗯\\n\\n25\\n00:01:29,408 --> 00:01:30,463\\n啊停咗雨啦\\n\\n26\\n00:01:30,521 --> 00:01:31,869\\n我要出去玩嘢食下嚇\\n\\n27\\n00:01:32,279 --> 00:01:32,513\\n哇\\n\\n28\\n00:01:32,572 --> 00:01:34,329\\n好嘢好啦有嘢食\\n\\n29\\n00:01:34,329 --> 00:01:35,325\\n你放心去咧\\n\\n30\\n00:01:35,383 --> 00:01:37,610\\n我會幫你看住佢哋嘅咧\\n\\n31\\n00:01:40,618 --> 00:01:43,000\\n爸爸拜爸爸\\n\\n32\\n00:01:44,162 --> 00:01:44,436\\n嗯\\n\\n33\\n00:01:44,546 --> 00:01:45,915\\n真係舒服\\n\\n34\\n00:01:47,504 --> 00:01:49,000\\n係啊哎呀哎呀哎呀哎呀\\n\\n35\\n00:01:50,339 --> 00:01:52,209\\n啊喂乜你噉霸王噶\\n\\n36\\n00:01:52,384 --> 00:01:53,319\\n乜嘢霸王啊\\n\\n37\\n00:01:53,436 --> 00:01:55,657\\n咪阻住我瞓覺啊快啲扯啊\\n\\n38\\n00:01:55,774 --> 00:01:58,170\\n你個頭係我哋嘅\\n\\n39\\n00:01:58,841 --> 00:01:59,905\\n你再唔走咧\\n\\n40\\n00:01:59,961 --> 00:02:01,584\\n繫唔係想大一身咁啊\\n\\n41\\n00:02:02,085 --> 00:02:02,417\\n啊\\n\\n42\\n00:02:07,018 --> 00:02:07,540\\n哈\\n\\n43\\n00:02:09,960 --> 00:02:10,387\\n誒啊啊\\n\\n44\\n00:02:10,982 --> 00:02:11,661\\n唉啊啊\\n\\n45\\n00:02:13,456 --> 00:02:13,780\\nok\\n\\n46\\n00:02:14,590 --> 00:02:14,980\\n嗯\\n\\n47\\n00:02:16,407 --> 00:02:16,742\\n哇\\n\\n48\\n00:02:17,746 --> 00:02:18,649\\n你快啲起身啊\\n\\n49\\n00:02:18,649 --> 00:02:19,325\\n你做咩霸咗\\n\\n50\\n00:02:19,325 --> 00:02:20,510\\n我個巢啊\\n\\n51\\n00:02:21,183 --> 00:02:22,362\\n你有冇搞錯啊\\n\\n52\\n00:02:22,474 --> 00:02:23,597\\n呢個頭邊度作住\\n\\n53\\n00:02:23,597 --> 00:02:24,440\\n你個名啊\\n\\n54\\n00:02:27,358 --> 00:02:28,980\\n你好快啲走啊\\n\\n55\\n00:02:33,428 --> 00:02:35,480\\n呢個就係雀巢勾戰嘅故事啦\\n\\n56\\n00:02:35,597 --> 00:02:37,765\\n如果話人無你強佔他人嘅嘢\\n\\n57\\n00:02:37,882 --> 00:02:40,051\\n就可以用雀巢勾佔呢句成語啦\\n\\n58\\n00:02:40,285 --> 00:02:40,696\\n喂喂\\n\\n59\\n00:02:40,696 --> 00:02:41,750\\n你明唔明白啊\\n\\n60\\n00:02:42,161 --> 00:02:43,274\\n博士我明白啦\\n\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_srt(transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pysrt import SubRipFile\n",
    "from pysrt import SubRipItem\n",
    "from pysrt import SubRipTime\n",
    "\n",
    "out = SubRipFile()\n",
    "\n",
    "for i, t in enumerate(transcription):\n",
    "  start = SubRipTime(seconds=t.start_time)\n",
    "  end = SubRipTime(seconds=t.end_time)\n",
    "  item = SubRipItem(index=i, start=start, end=end, text=t.text)\n",
    "  out.append(item)\n",
    "\n",
    "out.save('subtitles.srt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/josephcheng/Projects/yue-subtitle-api/.venv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Test whisper\n",
    "\n",
    "from faster_whisper import WhisperModel\n",
    "\n",
    "model_size = \"large-v3\"\n",
    "\n",
    "# Run on GPU with FP16\n",
    "model = WhisperModel(model_size, device=\"cpu\", compute_type=\"int8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments, info = model.transcribe(\"./Dragon Ball S01E008.mp3\", beam_size=5, language=\"yue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TranscriptionInfo(language='yue', language_probability=1, duration=1478.72, duration_after_vad=1478.72, all_language_probs=None, transcription_options=TranscriptionOptions(beam_size=5, best_of=5, patience=1, length_penalty=1, repetition_penalty=1, no_repeat_ngram_size=0, log_prob_threshold=-1.0, no_speech_threshold=0.6, compression_ratio_threshold=2.4, condition_on_previous_text=True, prompt_reset_on_temperature=0.5, temperatures=[0.0, 0.2, 0.4, 0.6, 0.8, 1.0], initial_prompt=None, prefix=None, suppress_blank=True, suppress_tokens=[-1], without_timestamps=False, max_initial_timestamp=1.0, word_timestamps=False, prepend_punctuations='\"\\'“¿([{-', append_punctuations='\"\\'.。,，!！?？:：”)]}、', max_new_tokens=None, clip_timestamps='0', hallucination_silence_threshold=None, hotwords=None), vad_options=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 掴摸!\n",
      " あのベンチャー\n",
      " 夢は空枠の間ぎっしり\n",
      " その鳥取の夢が乗せる\n",
      " この世のどこかで光ってる\n",
      " So it's me, Danny Ozeboy\n",
      " 妖怪宣言をぶっ飛ばし\n",
      " 雲のマシンで今日も飛ぶのさ\n",
      " Let's fly, fly, fly 馬鹿不思議\n",
      " 空を駆け抜け山を越え\n",
      " Let's fly, fly, fly 大冒険\n",
      " 不思議な旅が始まるぜ\n",
      " 手に入れろ ファンボール\n",
      " 世界一統的\n",
      " 雲に飛び込め\n",
      " 愛着你\n",
      " 追いかけろ\n",
      " 帆布尼\n",
      " 世界一統的\n",
      " 雲\n",
      " 雲\n",
      " 雲\n",
      " 雲\n",
      " 雲\n",
      " 雲\n",
      " 雲\n",
      " 雲\n",
      " 雲\n",
      " 雲\n",
      " 雲\n",
      " 雲\n",
      " 雲\n",
      " 雲\n",
      " 雲\n",
      " 雲\n",
      " 雲\n",
      " 雲\n",
      " 雲\n",
      " 雲\n",
      " 雲\n",
      " 雲\n",
      " 雲\n",
      " 雲\n",
      " 不可思議的芭蕉扇\n",
      " 吳空洞之子終於去到龜仙人住的島仔\n",
      " 我還以為是誰\n",
      " 原來之前收了我舊軍斗魂的弟弟\n",
      " 羅伯\n",
      " 你多好\n",
      " 我好好呀\n",
      " 阿伯就是武天老師了\n",
      " 龜仙人的龜波氣功\n",
      " 軍斗魂好好用呀 羅伯\n",
      " 咁咪當然啦\n",
      " 呢個軍斗魂係天神送畀我架喎\n",
      " 咁係好用\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m segment \u001b[38;5;129;01min\u001b[39;00m segments:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(segment\u001b[38;5;241m.\u001b[39mtext)\n",
      "File \u001b[0;32m~/Projects/yue-subtitle-api/.venv/lib/python3.8/site-packages/faster_whisper/transcribe.py:594\u001b[0m, in \u001b[0;36mWhisperModel.generate_segments\u001b[0;34m(self, features, tokenizer, options, encoder_output)\u001b[0m\n\u001b[1;32m    586\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m seek \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m encoder_output \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    587\u001b[0m     encoder_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode(segment)\n\u001b[1;32m    589\u001b[0m (\n\u001b[1;32m    590\u001b[0m     result,\n\u001b[1;32m    591\u001b[0m     avg_logprob,\n\u001b[1;32m    592\u001b[0m     temperature,\n\u001b[1;32m    593\u001b[0m     compression_ratio,\n\u001b[0;32m--> 594\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_with_fallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoder_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    596\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m options\u001b[38;5;241m.\u001b[39mno_speech_threshold \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    597\u001b[0m     \u001b[38;5;66;03m# no voice activity check\u001b[39;00m\n\u001b[1;32m    598\u001b[0m     should_skip \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mno_speech_prob \u001b[38;5;241m>\u001b[39m options\u001b[38;5;241m.\u001b[39mno_speech_threshold\n",
      "File \u001b[0;32m~/Projects/yue-subtitle-api/.venv/lib/python3.8/site-packages/faster_whisper/transcribe.py:884\u001b[0m, in \u001b[0;36mWhisperModel.generate_with_fallback\u001b[0;34m(self, encoder_output, prompt, tokenizer, options)\u001b[0m\n\u001b[1;32m    878\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    879\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    880\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbeam_size\u001b[39m\u001b[38;5;124m\"\u001b[39m: options\u001b[38;5;241m.\u001b[39mbeam_size,\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpatience\u001b[39m\u001b[38;5;124m\"\u001b[39m: options\u001b[38;5;241m.\u001b[39mpatience,\n\u001b[1;32m    882\u001b[0m     }\n\u001b[0;32m--> 884\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    886\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    887\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlength_penalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlength_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepetition_penalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepetition_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    889\u001b[0m \u001b[43m    \u001b[49m\u001b[43mno_repeat_ngram_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mno_repeat_ngram_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    891\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_scores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    892\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_no_speech_prob\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[43m    \u001b[49m\u001b[43msuppress_blank\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuppress_blank\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    894\u001b[0m \u001b[43m    \u001b[49m\u001b[43msuppress_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuppress_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    895\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_initial_timestamp_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_initial_timestamp_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    896\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    897\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    899\u001b[0m tokens \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39msequences_ids[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    901\u001b[0m \u001b[38;5;66;03m# Recover the average log prob from the returned score.\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for segment in segments:\n",
    "    print(\"[%.2fs -> %.2fs] %s\" % (segment.start, segment.end, segment.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "隻 0.0012368317\n",
      "只 0.010357974\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['但']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "model = bert_model.model\n",
    "tokenizer = bert_model.tokenizer\n",
    "\n",
    "text = \"龍[MASK]係傳說中嘅動物豬皮萬噹然等唔到龍出嚟\"\n",
    "model_inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "test1_label = \"隻\"\n",
    "test2_label = \"只\"\n",
    "test1_index = tokenizer.convert_tokens_to_ids(test1_label)\n",
    "test2_index = tokenizer.convert_tokens_to_ids(test2_label)\n",
    "mask_index = model_inputs.input_ids[0].tolist().index(tokenizer.mask_token_id)\n",
    "vocab_size = len(tokenizer.get_vocab())\n",
    "inputs_onnx = {k: v.cpu().detach().numpy()\n",
    "                for k, v in model_inputs.items()}\n",
    "predictions = model.run(None, inputs_onnx)\n",
    "lm_logits = predictions[0]\n",
    "# softmax\n",
    "lm_logits = np.exp(lm_logits) / np.exp(lm_logits).sum(-1, keepdims=True)\n",
    "# argmax\n",
    "pred = np.argmax(lm_logits, axis=-1)[0, mask_index]\n",
    "\n",
    "print(test1_label, lm_logits[0, mask_index, test1_index])\n",
    "print(test2_label, lm_logits[0, mask_index, test2_index])\n",
    "tokenizer.convert_ids_to_tokens([pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'龍只系傳說中嘅動物豬皮萬當然等唔到龍出嚟'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_dict = load_dict()\n",
    "corrector('龙只系传说中嘅动物猪皮万当然等唔到龙出嚟', char_dict, bert_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/josephcheng/Projects/yue-subtitle-api/.venv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from utils import aligner, special_token_ids, punct_labels, SAMPLE_RATE, TranscribeResult, asr_model, LanguageModel, bert_model, t2s_char_dict\n",
    "\n",
    "from typing import List, Union, Literal, Tuple\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "UNK_ID = 0\n",
    "\n",
    "def asr(\n",
    "    wav_content: Union[str, np.ndarray, List[str]],\n",
    "    language=\"yue\",\n",
    "    textnorm: Union[Literal[\"withitn\", \"woitn\"]] = \"withitn\",\n",
    ") -> List[\"TranscribeResult\"]:\n",
    "    language_input = language\n",
    "    textnorm_input = textnorm\n",
    "    language_list, textnorm_list = asr_model.read_tags(language_input, textnorm_input)\n",
    "    waveform = asr_model.load_data(\n",
    "        wav_content, asr_model.frontend.opts.frame_opts.samp_freq\n",
    "    )\n",
    "    feats, feats_len = asr_model.extract_feat(waveform)\n",
    "    _language_list = language_list[0:1]\n",
    "    _textnorm_list = textnorm_list[0:1]\n",
    "    segments = []\n",
    "    results = []\n",
    "\n",
    "    ctc_logits, encoder_out_lens = asr_model.infer(\n",
    "        feats,\n",
    "        feats_len,\n",
    "        np.array(_language_list, dtype=np.int32),\n",
    "        np.array(_textnorm_list, dtype=np.int32),\n",
    "    )\n",
    "    ctc_logits = torch.from_numpy(ctc_logits).float()\n",
    "    ratio = waveform[0].shape[0] / ctc_logits.size(1) / SAMPLE_RATE\n",
    "    # support batch_size=1 only currently\n",
    "    x = ctc_logits[0]\n",
    "    # log_softmax\n",
    "    emissions = torch.nn.functional.log_softmax(x, dim=-1)\n",
    "    yseq = emissions.argmax(dim=-1)\n",
    "    yseq = torch.unique_consecutive(yseq, dim=-1)\n",
    "    mask = yseq != asr_model.blank_id\n",
    "    preds = yseq[mask]\n",
    "    token_spans = aligner(emissions, preds.unsqueeze(0))[0]\n",
    "\n",
    "    for token_span in token_spans:\n",
    "        label = asr_model.tokenizer.sp.IdToPiece(token_span.token)\n",
    "\n",
    "        if token_span.token in special_token_ids:\n",
    "            continue\n",
    "\n",
    "        # get top 8 candidates\n",
    "        candidates = []\n",
    "        token_emissions = emissions[token_span.start : token_span.end,]\n",
    "        token_emissions[:, UNK_ID] = float(\"-inf\")\n",
    "        topk_tokens = torch.topk(token_emissions, 8)\n",
    "\n",
    "        for i in range(topk_tokens.indices.size(0)):\n",
    "            candidate_chars = [asr_model.tokenizer.sp.IdToPiece(token_id) for token_id in topk_tokens.indices[i].tolist()]\n",
    "            candidate_probs = [k.item() for k in topk_tokens.values[i]]\n",
    "            candidates = list(zip(candidate_chars, candidate_probs))\n",
    "\n",
    "        segments.append(\n",
    "            TranscribeResult(\n",
    "                text=label,\n",
    "                start_time=token_span.start * ratio,\n",
    "                end_time=token_span.end * ratio,\n",
    "                candidates=candidates,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    start_idx = 0\n",
    "    end_idx = 1\n",
    "\n",
    "    while end_idx < len(segments):\n",
    "        current_segment = segments[end_idx]\n",
    "\n",
    "        if current_segment.text in punct_labels:\n",
    "            results.append(\n",
    "                TranscribeResult(\n",
    "                    text=\"\".join(\n",
    "                        [segment.text for segment in segments[start_idx:end_idx]]\n",
    "                    ),\n",
    "                    start_time=segments[start_idx].start_time,\n",
    "                    end_time=segments[end_idx].end_time,\n",
    "                )\n",
    "            )\n",
    "            start_idx = end_idx + 1\n",
    "\n",
    "        end_idx += 1\n",
    "\n",
    "    return results, segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TranscribeResult(text=亦有根斗云你系天神送俾我噶噃梗系好用, start_time=0.3390535714285714, end_time=3.5600625), candidates=[]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[TranscribeResult(text=亦, start_time=0.3390535714285714, end_time=0.3955625), candidates=[亦(-1.60), 一(-1.80), 益(-2.30), 呢(-2.35), 啲(-2.71), 即(-3.24), 都(-3.49), 经(-3.64)],\n",
       " TranscribeResult(text=有, start_time=0.5085803571428571, end_time=0.5650892857142857), candidates=[有(-0.43), 又(-2.68), 由(-3.57), 头(-3.84), 旧(-3.87), 个(-3.91), 油(-3.98), 度(-4.28)],\n",
       " TranscribeResult(text=根, start_time=0.6215982142857143, end_time=0.6781071428571428), candidates=[根(-1.25), 筋(-1.59), 跟(-1.73), 间(-1.91), 斤(-2.69), 金(-4.18), 耕(-4.31), 关(-4.68)],\n",
       " TranscribeResult(text=斗, start_time=0.791125, end_time=0.8476339285714286), candidates=[斗(-0.04), 抖(-4.33), 豆(-6.10), 九(-6.27), 头(-6.28), 窦(-6.32), 走(-6.81), 到(-6.85)],\n",
       " TranscribeResult(text=云, start_time=0.9606517857142857, end_time=1.0171607142857142), candidates=[云(-0.43), 匀(-1.94), 晕(-2.05), 魂(-3.25), 运(-5.16), 纹(-5.59), 横(-6.02), 痕(-6.13)],\n",
       " TranscribeResult(text=你, start_time=1.0736696428571428, end_time=1.1301785714285715), candidates=[你(-1.12), 呢(-1.42), 咧(-1.58), 嚟(-2.89), 嘞(-3.34), 啊(-3.84), 嘅(-4.26), 理(-4.63)],\n",
       " TranscribeResult(text=系, start_time=1.2997053571428572, end_time=1.3562142857142856), candidates=[系(-0.01), 喺(-5.63), 是(-7.97), 啊(-8.34), 睇(-9.50), 阿(-9.51), 诶(-9.66), 佢(-10.06)],\n",
       " TranscribeResult(text=天, start_time=1.4127232142857142, end_time=1.4692321428571429), candidates=[天(-0.00), 听(-8.65), 癫(-8.93), 先(-8.93), 千(-9.21), 啲(-9.51), 牵(-9.67), 添(-10.03)],\n",
       " TranscribeResult(text=神, start_time=1.58225, end_time=1.6387589285714286), candidates=[神(-0.09), 臣(-3.14), 成(-4.17), 辰(-4.71), 使(-5.58), 晨(-6.21), 才(-6.51), 上(-7.02)],\n",
       " TranscribeResult(text=送, start_time=1.7517767857142856, end_time=1.8082857142857143), candidates=[送(-0.00), 宋(-9.20), 输(-9.50), 松(-9.86), 崇(-10.38), 供(-10.39), 数(-11.14), 素(-11.17)],\n",
       " TranscribeResult(text=俾, start_time=1.9213035714285713, end_time=1.9778125), candidates=[俾(-0.03), 畀(-5.40), 边(-6.01), 给(-6.19), 兵(-6.31), 比(-7.27), 冰(-7.27), 逼(-8.04)],\n",
       " TranscribeResult(text=我, start_time=2.090830357142857, end_time=2.2038482142857143), candidates=[我(-0.01), 个(-7.20), ，(-7.45), 嗰(-7.89), 佢(-8.15), 学(-8.26), 好(-8.42), 国(-8.62)],\n",
       " TranscribeResult(text=噶, start_time=2.260357142857143, end_time=2.3168660714285716), candidates=[噶(-0.59), 嘅(-1.06), 个(-2.89), 嗰(-4.81), 咯(-5.30), 啊(-6.21), 嘎(-6.22), 啫(-6.61)],\n",
       " TranscribeResult(text=噃, start_time=2.4298839285714284, end_time=2.486392857142857), candidates=[噃(-0.35), 咯(-4.38), 啵(-5.03), 喔(-5.40), 啦(-5.49), 嘛(-5.71), 嘞(-6.20), 啊(-6.68)],\n",
       " TranscribeResult(text=梗, start_time=2.712428571428571, end_time=2.7689375), candidates=[梗(-0.21), 咁(-2.14), 哽(-2.98), 简(-5.17), 紧(-5.24), 讲(-5.78), 拣(-5.91), 硬(-6.66)],\n",
       " TranscribeResult(text=系, start_time=2.881955357142857, end_time=2.9384642857142858), candidates=[系(-0.02), 啊(-4.67), 嘅(-5.54), 咪(-6.53), 噶(-6.94), 诶(-7.20), 就(-7.46), 梗(-7.49)],\n",
       " TranscribeResult(text=好, start_time=3.051482142857143, end_time=3.1079910714285712), candidates=[好(-0.01), 冇(-5.07), 有(-7.14), 可(-8.27), 口(-9.19), 何(-9.40), 系(-9.61), 我(-9.97)],\n",
       " TranscribeResult(text=用, start_time=3.1645, end_time=3.2210089285714285), candidates=[用(-0.00), 勇(-6.73), 样(-7.25), 容(-8.21), 有(-8.76), 咁(-8.94), 佣(-8.97), 运(-9.03)],\n",
       " TranscribeResult(text=。, start_time=3.5035535714285713, end_time=3.5600625), candidates=[。(-0.01), ？(-5.26), .(-10.16), ！(-11.37), ，(-12.30), ?(-13.88), !(-14.33), 系(-17.08)]]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result, segments = asr('dragonball_test1.mp3')\n",
    "\n",
    "print(result)\n",
    "segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['舊', '嚿']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2s_char_dict['旧']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 53\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;66;03m# if len(text_candidates) == 0:\u001b[39;00m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;66;03m#     return text\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;66;03m#     x for _, x in sorted(zip(scores, text_candidates), key=lambda pair: pair[0])\u001b[39;00m\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;66;03m# ]\u001b[39;00m\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m text_candidates\n\u001b[0;32m---> 53\u001b[0m \u001b[43mbeam_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43msegments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbert_model\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[8], line 29\u001b[0m, in \u001b[0;36mbeam_search\u001b[0;34m(segments, lm_model)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t, curr_ppl \u001b[38;5;129;01min\u001b[39;00m text_candidates:\n\u001b[1;32m     28\u001b[0m     text \u001b[38;5;241m=\u001b[39m t \u001b[38;5;241m+\u001b[39m c\n\u001b[0;32m---> 29\u001b[0m     perplexity \u001b[38;5;241m=\u001b[39m \u001b[43mlm_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mperplexity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m     new_ppl \u001b[38;5;241m=\u001b[39m curr_ppl \u001b[38;5;241m+\u001b[39m perplexity\n\u001b[1;32m     31\u001b[0m     new_candidates\u001b[38;5;241m.\u001b[39mappend((text, new_ppl))\n",
      "File \u001b[0;32m~/Projects/yue-subtitle-api/utils.py:307\u001b[0m, in \u001b[0;36mBertModel.perplexity\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mperplexity\u001b[39m(\u001b[38;5;28mself\u001b[39m, text: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[0;32m--> 307\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    308\u001b[0m     perplexity \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexp(loss)\n\u001b[1;32m    310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m perplexity\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/Projects/yue-subtitle-api/utils.py:297\u001b[0m, in \u001b[0;36mBertModel.get_loss\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    295\u001b[0m labels \u001b[38;5;241m=\u001b[39m model_inputs\u001b[38;5;241m.\u001b[39minput_ids\n\u001b[1;32m    296\u001b[0m inputs_onnx \u001b[38;5;241m=\u001b[39m {k: v\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m model_inputs\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m--> 297\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs_onnx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    298\u001b[0m lm_logits \u001b[38;5;241m=\u001b[39m predictions[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    299\u001b[0m lm_logits \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(lm_logits)\n",
      "File \u001b[0;32m~/Projects/yue-subtitle-api/.venv/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:220\u001b[0m, in \u001b[0;36mSession.run\u001b[0;34m(self, output_names, input_feed, run_options)\u001b[0m\n\u001b[1;32m    218\u001b[0m     output_names \u001b[38;5;241m=\u001b[39m [output\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_outputs_meta]\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_feed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m C\u001b[38;5;241m.\u001b[39mEPFail \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_fallback:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def beam_search(segments: List[TranscribeResult], lm_model: LanguageModel) -> str:\n",
    "    # make all possible candidates for beam search\n",
    "    char_candidates: List[List[Tuple[str, float]]] = []\n",
    "\n",
    "    # swapping candidates\n",
    "    for i, segment in enumerate(segments):\n",
    "        char_candidates.append([])\n",
    "\n",
    "        for candidate, prob in segment.candidates:\n",
    "            if prob < -7:\n",
    "                continue\n",
    "\n",
    "            if candidate in t2s_char_dict:\n",
    "                for c in t2s_char_dict[candidate]:\n",
    "                    char_candidates[i].append((c, prob))\n",
    "            else:\n",
    "                char_candidates[i].append((candidate, prob))\n",
    "\n",
    "    text_candidates: List[Tuple[str, float]] = []\n",
    "\n",
    "    for i, candidates in enumerate(char_candidates):\n",
    "        if i == 0:\n",
    "            text_candidates = [(c[0], 0) for c in candidates]\n",
    "        else:\n",
    "            new_candidates = []\n",
    "            for c, _ in candidates:\n",
    "                for t, curr_ppl in text_candidates:\n",
    "                    text = t + c\n",
    "                    perplexity = lm_model.perplexity(text)\n",
    "                    new_ppl = curr_ppl + perplexity\n",
    "                    new_candidates.append((text, new_ppl))\n",
    "            new_candidates.sort(key=lambda x: x[1])\n",
    "            # get last n best candidates\n",
    "            new_candidates = new_candidates[:20]\n",
    "            text_candidates = new_candidates\n",
    "\n",
    "    return text_candidates\n",
    "\n",
    "beam_search(segments, bert_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.114457922600018"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_model.perplexity('呢嚿')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'logits' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m token_id1 \u001b[38;5;241m=\u001b[39m asr_model\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39msp\u001b[38;5;241m.\u001b[39mPieceToId(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m呢\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m token_id2 \u001b[38;5;241m=\u001b[39m asr_model\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39msp\u001b[38;5;241m.\u001b[39mPieceToId(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m亦\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28mprint\u001b[39m(token_id1, \u001b[43mlogits\u001b[49m[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, token_id1])\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(token_id2, logits[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, token_id2])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'logits' is not defined"
     ]
    }
   ],
   "source": [
    "token_id1 = asr_model.tokenizer.sp.PieceToId('呢')\n",
    "token_id2 = asr_model.tokenizer.sp.PieceToId('亦')\n",
    "\n",
    "print(token_id1, logits[0, 1, token_id1])\n",
    "print(token_id2, logits[0, 1, token_id2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|ANGRY|>'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "token_spans = pickle.load(open('token_spans.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24888 0 1\n",
      "25003 1 2\n",
      "24993 2 3\n",
      "25016 3 4\n",
      "10880 6 7\n",
      "13295 8 9\n",
      "15677 11 12\n",
      "13112 14 15\n",
      "10016 17 18\n",
      "10923 19 20\n",
      "15875 23 24\n",
      "11543 25 26\n",
      "15457 28 29\n",
      "18232 31 32\n",
      "10241 34 35\n",
      "12624 37 39\n",
      "11202 40 41\n",
      "11181 43 44\n",
      "13527 48 49\n",
      "15875 51 52\n",
      "11590 54 55\n",
      "14938 56 57\n",
      "9729 62 63\n"
     ]
    }
   ],
   "source": [
    "for token_span in token_spans:\n",
    "  print(token_span.token, token_span.start, token_span.end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
